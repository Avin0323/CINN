{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Load and Execute Paddle Model\n\nIn this tutorial, we will show you how to load and execute a paddle model in CINN.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import cinn\nfrom cinn import *\nfrom cinn.frontend import *\nfrom cinn.framework import *\nfrom cinn.common import *\nimport numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare to Load Model\nDeclare the params and prepare to load and execute the paddle model.\n\n- :code:`enable_gpu` implies whether to run CINN on CUDA backends.\n\n- :code:`mnodel_dir` is the path where the paddle model is stored.\n\n- :code:`input_tensor` is the name of input tensor in the model.\n\n- :code:`target_tensor` is the name of output tensor we want.\n\n- :code:`x_shape` is the input tensor's shape of the model\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "enable_gpu = \"OFF\"\nmodel_dir = \"./ResNet18\"\ninput_tensor = 'image'\ntarget_tensor = 'save_infer_model/scale_0'\nx_shape = [2, 3, 224, 224]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the target backend\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "if enable_gpu == \"ON\":\n    target = DefaultNVGPUTarget()\nelse:\n    target = DefaultHostTarget()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set the input tensor and init interpreter\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "executor = Interpreter([input_tensor], [x_shape])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Model to CINN\nLoad the paddle model and transform it into CINN IR\n\n* :code:`mnodel_dir` is the path where the paddle model is stored.\n\n* :code:`target` is the backend to execute model on.\n\n* :code:`params_combined` implies whether the params of paddle\nmodel is stored in one file.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params_combined = True\nexecutor.load_paddle_model(model_dir, target, params_combined)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get input tensor and set input data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "a_t = executor.get_tensor(input_tensor)\nx_data = np.random.random(x_shape).astype(\"float32\")\na_t.from_numpy(x_data, target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Get output tensor and init its data to zero.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "out = executor.get_tensor(target_tensor)\nout.from_numpy(np.zeros(out.shape(), dtype='float32'), target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Execute Model\nExecute the model and get output tensor's data.\n* :code:`out` is the data of output tensor we want.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "executor.run()\nout = out.numpy(target)\nprint(\"Execution Done!\\nResult shape is:\\n\", out.shape)\nprint(\"Result data is:\\n\", out)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}