
.. _program_listing_file__home_chunwei_project_cinn2_cinn_hlir_pe_reduction.cc:

Program Listing for File reduction.cc
=====================================

|exhale_lsh| :ref:`Return to documentation for file <file__home_chunwei_project_cinn2_cinn_hlir_pe_reduction.cc>` (``/home/chunwei/project/cinn2/cinn/hlir/pe/reduction.cc``)

.. |exhale_lsh| unicode:: U+021B0 .. UPWARDS ARROW WITH TIP LEFTWARDS

.. code-block:: cpp

   #include "cinn/hlir/pe/reduction.h"
   
   #include <cinn/ir/ir_base.h>
   
   #include "cinn/common/ir_util.h"
   #include "cinn/hlir/pe/broadcast.h"
   #include "cinn/ir/ir_operators.h"
   #include "cinn/ir/tensor.h"
   #include "cinn/lang/builtin.h"
   #include "cinn/lang/compute.h"
   
   namespace cinn {
   namespace hlir {
   namespace pe {
   
   using lang::Compute;
   using poly::StageMap;
   using namespace ir;
   
   void GetRealAxes(int ndim, const std::vector<Expr>& axes, std::vector<int>* real_axes) {
     CHECK(real_axes);
     if (axes.empty()) {
       for (int i = 0; i < ndim; ++i) {
         real_axes->push_back(i);
       }
     } else {
       for (auto axis : axes) {
         auto val = axis.as_int32();
         if (val < 0) {
           val += ndim;
         }
         CHECK_LE(val, ndim) << "exceeds the maximum dimension: " << ndim << std::endl;
         CHECK_GE(val, 0);
         real_axes->push_back(val);
       }
       real_axes->resize(std::unique(real_axes->begin(), real_axes->end()) - real_axes->begin());
       std::sort(real_axes->begin(), real_axes->end());
     }
   }
   
   void GetOutputShape(const std::vector<int>& real_axes,
                       std::vector<Expr>* output_shape,
                       const Tensor& tensor,
                       bool keep_dims) {
     CHECK(output_shape);
     auto ndim = tensor->shape.size();
     if (keep_dims) {
       for (size_t i = 0; i < ndim; ++i) {
         if (std::find(real_axes.begin(), real_axes.end(), i) != real_axes.end()) {
           output_shape->push_back(common::make_one());
         } else {
           output_shape->push_back(tensor->shape[i]);
         }
       }
     } else {
       for (size_t i = 0; i < ndim; ++i) {
         if (std::find(real_axes.begin(), real_axes.end(), i) == real_axes.end()) {
           output_shape->push_back(tensor->shape[i]);
         }
       }
     }
     if (output_shape->empty()) {
       output_shape->push_back(common::make_one());
     }
   }
   
   template <typename FuncOp>
   Tensor DoReduce(const Tensor& tensor,
                   poly::StageMap stages,
                   const FuncOp& fn,
                   const std::vector<Expr>& output_shape,
                   const std::vector<int>& real_axes,
                   const std::vector<int>& squeeze_axes,
                   const ir::Expr& initial,
                   const std::string& output_name) {
     std::vector<Var> reduce_axes;
     for (auto& axis : real_axes) {
       std::string name = UniqName("kk");
       reduce_axes.push_back(Var(tensor->shape[axis], name));
     }
     auto compute = [&](const std::vector<Expr>& indices) -> Expr {
       std::vector<Expr> eval_indice;
       int indice_cnt = 0;
       int reduce_cnt = 0;
   
       for (size_t i = 0; i < tensor->shape.size(); ++i) {
         bool squeeze_i = std::find(squeeze_axes.begin(), squeeze_axes.end(), i) != squeeze_axes.end();
         if (std::find(real_axes.begin(), real_axes.end(), i) != real_axes.end()) {
           eval_indice.push_back(reduce_axes[reduce_cnt]);
           reduce_cnt++;
           indice_cnt += !squeeze_i;
           continue;
         }
         eval_indice.push_back(indices[indice_cnt]);
         indice_cnt++;
       }
       return fn(tensor(eval_indice), reduce_axes, initial);
     };
   
     Tensor C = Compute(output_shape, compute, output_name);
     stages->InsertLazily(C);
     return C;
   }
   
   template <typename FuncOp>
   Tensor Reduce(const Tensor& tensor,
                 poly::StageMap stages,
                 const std::vector<Expr>& axes,
                 const FuncOp& fn,
                 bool keep_dims,
                 const ir::Expr& initial,
                 const std::string& output_name) {
     auto ndim = tensor->shape.size();
     CHECK_NE(ndim, 0) << "Reduce tensor's dim must be more than 0";
     std::vector<int> real_axes;
     GetRealAxes(static_cast<int>(ndim), axes, &real_axes);
     std::vector<Expr> output_shapes;
     GetOutputShape(real_axes, &output_shapes, tensor, keep_dims);
     return DoReduce(
         tensor, stages, fn, output_shapes, real_axes, keep_dims ? std::vector<int>() : real_axes, initial, output_name);
   }
   
   Tensor Sum(const Tensor& A,
              poly::StageMap stages,
              const std::vector<Expr>& axes,
              bool keep_dims,
              const ir::Expr& initial,
              const std::string& output_name) {
     return Reduce(A, stages, axes, lang::ReduceSum, keep_dims, initial, output_name);
   }
   
   Tensor Prod(const Tensor& A,
               poly::StageMap stages,
               const std::vector<Expr>& axes,
               bool keep_dims,
               const ir::Expr& initial,
               const std::string& output_name) {
     return Reduce(A, stages, axes, lang::ReduceMul, keep_dims, initial, output_name);
   }
   
   Tensor Max(
       const Tensor& A, StageMap stages, const std::vector<Expr>& axes, bool keep_dims, const std::string& output_name) {
     return Reduce(A, stages, axes, lang::ReduceMax, keep_dims, Expr(), output_name);
   }
   
   Tensor Min(
       const Tensor& A, StageMap stages, const std::vector<Expr>& axes, bool keep_dims, const std::string& output_name) {
     return Reduce(A, stages, axes, lang::ReduceMin, keep_dims, Expr(), output_name);
   }
   
   }  // namespace pe
   }  // namespace hlir
   }  // namespace cinn
